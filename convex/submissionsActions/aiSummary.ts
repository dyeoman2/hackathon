'use node';

import { GetObjectCommand, ListObjectsV2Command, S3Client } from '@aws-sdk/client-s3';
import { v } from 'convex/values';
import { internal } from '../_generated/api';
import type { Id } from '../_generated/dataModel';
import type { ActionCtx } from '../_generated/server';
import { internalAction } from '../_generated/server';
import { guarded } from '../authz/guardFactory';
import { checkAISearchJobStatus, downloadAndUploadRepoHelper } from './repoProcessing';
import type {
  CheckCloudflareIndexingRef,
  ContinueCloudflareIndexingRef,
  GenerateSummaryRef,
  GetSubmissionInternalRef,
  UpdateSubmissionAIInternalRef,
  UpdateSubmissionSourceInternalRef,
} from './types';

type CloudflareFolderFilter = {
  type: 'and';
  filters: Array<{
    type: 'gt' | 'gte' | 'lt' | 'lte' | 'eq';
    key: string;
    value: string;
  }>;
};

function buildFolderFilter(
  r2PathPrefix: string,
  submissionId?: Id<'submissions'>,
): CloudflareFolderFilter {
  const normalizedPrefix = r2PathPrefix.replace(/\/$/, '');
  const filters: CloudflareFolderFilter['filters'] = [
    {
      type: 'gt',
      key: 'folder',
      value: `${normalizedPrefix}/`,
    },
    {
      type: 'lte',
      key: 'folder',
      value: `${normalizedPrefix}z`,
    },
  ];

  if (submissionId) {
    filters.push({
      type: 'eq',
      key: 'file.submissionid',
      value: submissionId,
    });
  }

  return {
    type: 'and',
    filters,
  };
}

type CloudflareJobStatus = Awaited<ReturnType<typeof checkAISearchJobStatus>>;

/**
 * Internal action to check if files are indexed in Cloudflare AI Search
 * Uses Convex scheduler to poll without blocking - reschedules itself if not ready
 * Once indexing is complete, marks the submission as complete and generates score if needed
 * Note: Summary is already generated by generateSummary, so we don't generate another one here
 * Also handles download/upload if the repo hasn't been uploaded yet
 */
export const checkCloudflareIndexing = internalAction({
  args: {
    submissionId: v.id('submissions'),
    attempt: v.number(),
    forceRegenerate: v.optional(v.boolean()), // If true, regenerate even if summary exists
  },
  handler: async (ctx, args) => {
    try {
      // Sync jobs can take up to 10 minutes, so we need enough attempts to cover that
      // With exponential backoff (15s to 30s), ~100 attempts covers ~25 minutes
      const maxAttempts = 100; // Maximum 100 attempts (~25 minutes total)
      // Exponential backoff: start with 15 seconds, increase gradually (AI search takes 45+ seconds minimum)
      const pollIntervalMs = Math.min(15000 + args.attempt * 1000, 30000); // 15s to 30s max

      // Get submission
      const submission = await ctx.runQuery(
        (internal.submissions as unknown as { getSubmissionInternal: GetSubmissionInternalRef })
          .getSubmissionInternal,
        {
          submissionId: args.submissionId,
        },
      );

      if (!submission) {
        throw new Error('Submission not found');
      }

      // Early exit: If summary already exists and we're not forcing regeneration, we're done
      // Check if processing is already complete to avoid unnecessary retries
      // This prevents the function from continuing to retry after completion
      // BUT: If forceRegenerate is true, always regenerate regardless of existing summary
      const hasSummary = !!submission.source?.aiSummary;
      const isComplete = submission.source?.processingState === 'complete';
      const hasRecordedSyncCompletion =
        typeof submission.source?.aiSearchSyncCompletedAt === 'number';

      if (hasSummary && isComplete && !args.forceRegenerate) {
        console.log(
          `[AI Search] Submission ${args.submissionId} already has summary - skipping (attempt ${args.attempt})`,
        );
        return; // Already complete, don't reschedule (unless forcing regeneration)
      }

      // If forcing regeneration, clear existing summary first
      if (args.forceRegenerate && hasSummary) {
        console.log(
          `[AI Search] Force regenerating summary for submission ${args.submissionId} - clearing existing summary`,
        );
        await ctx.runMutation(
          (
            internal.submissions as unknown as {
              updateSubmissionSourceInternal: UpdateSubmissionSourceInternalRef;
            }
          ).updateSubmissionSourceInternal,
          {
            submissionId: args.submissionId,
            aiSummary: undefined,
            summarizedAt: undefined,
            summaryGenerationStartedAt: undefined,
            summaryGenerationCompletedAt: undefined,
            processingState: 'indexing', // Reset to indexing state
          },
        );
        await ctx.runMutation(
          (
            internal.submissions as unknown as {
              updateSubmissionAIInternal: UpdateSubmissionAIInternalRef;
            }
          ).updateSubmissionAIInternal,
          {
            submissionId: args.submissionId,
            summary: undefined,
          },
        );
      }

      // Check if we have summary but processing state isn't marked complete - fix the state
      if (hasSummary && !isComplete && hasRecordedSyncCompletion) {
        console.log(
          `[AI Search] Submission ${args.submissionId} has summary and recorded sync completion but state not complete - fixing state`,
        );
        await ctx.runMutation(
          (
            internal.submissions as unknown as {
              updateSubmissionSourceInternal: UpdateSubmissionSourceInternalRef;
            }
          ).updateSubmissionSourceInternal,
          {
            submissionId: args.submissionId,
            processingState: 'complete',
          },
        );
        return; // State fixed, we're done
      }

      // If repo hasn't been uploaded, do it now (same file, can call helper directly)
      if (!submission.source?.r2Key) {
        await downloadAndUploadRepoHelper(ctx, {
          submissionId: args.submissionId,
        });

        // After upload, wait longer for files to be indexed by Cloudflare AI Search
        // AI Search indexing can take 45+ seconds minimum
        if (args.attempt === 0) {
          // First attempt after upload, wait longer before checking indexing
          await ctx.scheduler.runAfter(
            45000, // Wait 45 seconds for files to be indexed
            (
              internal.submissionsActions.aiSummary as unknown as {
                checkCloudflareIndexing: CheckCloudflareIndexingRef;
              }
            ).checkCloudflareIndexing,
            {
              submissionId: args.submissionId,
              attempt: 1, // Start at attempt 1 after initial wait
              forceRegenerate: args.forceRegenerate ?? false,
            },
          );
          return;
        }
      }

      // At this point, source.r2Key should exist (either was already there or just uploaded)
      // But TypeScript doesn't know that, so we need to check again
      if (!submission.source?.r2Key) {
        throw new Error('Repository files not uploaded to R2');
      }

      // Get AI Search instance ID from env
      const aiSearchInstanceId = process.env.CLOUDFLARE_AI_SEARCH_INSTANCE_ID;
      const accountId = process.env.CLOUDFLARE_ACCOUNT_ID;
      const apiToken = process.env.CLOUDFLARE_API_TOKEN;

      if (!aiSearchInstanceId || !accountId || !apiToken) {
        throw new Error('Cloudflare AI Search not configured');
      }

      // R2 path prefix for this submission (e.g., "repos/{submissionId}/files/")
      // We've already checked that source.r2Key exists above
      const r2PathPrefix = submission.source.r2Key;
      const uploadedAt = submission.source?.uploadedAt || 0;
      const timeSinceUpload = Date.now() - uploadedAt;

      // Log timing information for debugging
      console.log(
        `[AI Search] Checking indexing for submission ${args.submissionId}, attempt ${args.attempt}/${maxAttempts}`,
      );
      console.log(
        `[AI Search] Files uploaded ${Math.round(timeSinceUpload / 1000)}s ago, path prefix: ${r2PathPrefix}`,
      );

      // If files were just uploaded (less than 60 seconds ago), wait longer
      // Cloudflare AI Search indexing can take 45+ seconds after R2 upload
      if (timeSinceUpload > 0 && timeSinceUpload < 60000 && args.attempt < 5) {
        console.log(
          `[AI Search] Files uploaded recently (${Math.round(timeSinceUpload / 1000)}s ago), waiting longer before checking indexing...`,
        );
        await ctx.scheduler.runAfter(
          Math.max(60000 - timeSinceUpload, 15000), // Wait until at least 60s have passed
          (
            internal.submissionsActions.aiSummary as unknown as {
              checkCloudflareIndexing: CheckCloudflareIndexingRef;
            }
          ).checkCloudflareIndexing,
          {
            submissionId: args.submissionId,
            attempt: args.attempt + 1,
            forceRegenerate: args.forceRegenerate ?? false,
          },
        );
        return;
      }

      // Set processing state to indexing if not already set
      if (submission.source?.processingState !== 'indexing') {
        await ctx.runMutation(
          (
            internal.submissions as unknown as {
              updateSubmissionSourceInternal: UpdateSubmissionSourceInternalRef;
            }
          ).updateSubmissionSourceInternal,
          {
            submissionId: args.submissionId,
            processingState: 'indexing',
          },
        );
      }

      // Check if files are indexed by checking job status first, then falling back to querying documents
      let indexed = false;
      let jobStatus: CloudflareJobStatus = null;
      let waitForJobCompletion = false;

      // Log current state for debugging
      console.log(
        `[AI Search] Checking indexing status for submission ${args.submissionId} (attempt ${args.attempt}/${maxAttempts})`,
      );
      console.log(`[AI Search] Current state:`, {
        processingState: submission.source?.processingState,
        hasJobId: !!submission.source?.aiSearchSyncJobId,
        jobId: submission.source?.aiSearchSyncJobId,
        syncStartedAt: submission.source?.aiSearchSyncStartedAt
          ? new Date(submission.source.aiSearchSyncStartedAt).toISOString()
          : null,
        syncCompletedAt: submission.source?.aiSearchSyncCompletedAt
          ? new Date(submission.source.aiSearchSyncCompletedAt).toISOString()
          : null,
        uploadedAt: submission.source?.uploadedAt
          ? new Date(submission.source.uploadedAt).toISOString()
          : null,
        timeSinceUpload: timeSinceUpload > 0 ? `${Math.round(timeSinceUpload / 1000)}s` : 'N/A',
        r2PathPrefix,
      });

      // If sync completion time is already recorded, assume indexing is complete
      // This handles cases where indexing was confirmed in a previous attempt
      if (submission.source?.aiSearchSyncCompletedAt) {
        console.log(
          `[AI Search] ‚úÖ Sync completion already recorded at ${new Date(submission.source.aiSearchSyncCompletedAt).toISOString()} - assuming indexing is complete`,
        );
        indexed = true;
      }

      // First, try to check job status if we have a job_id and indexing isn't already confirmed
      if (!indexed && submission.source?.aiSearchSyncJobId) {
        console.log(
          `[AI Search] Checking job status for job ${submission.source.aiSearchSyncJobId}...`,
        );
        jobStatus = await checkAISearchJobStatus(ctx, submission.source.aiSearchSyncJobId);
        console.log(
          `[AI Search] Job ${submission.source.aiSearchSyncJobId} status: ${jobStatus || 'unknown (null)'}`,
        );

        if (jobStatus === 'completed') {
          console.log(`[AI Search] ‚úÖ Sync job completed - files should be indexed`);
          indexed = true;
          // Record sync completion time
          const completedAt = Date.now();
          console.log(
            `[AI Search] Recording sync completion time: ${new Date(completedAt).toISOString()}`,
          );
          await ctx.runMutation(
            (
              internal.submissions as unknown as {
                updateSubmissionSourceInternal: UpdateSubmissionSourceInternalRef;
              }
            ).updateSubmissionSourceInternal,
            {
              submissionId: args.submissionId,
              aiSearchSyncCompletedAt: completedAt,
            },
          );
          console.log(`[AI Search] ‚úÖ Sync completion recorded successfully`);
        } else if (jobStatus === 'failed') {
          console.warn(`[AI Search] ‚ö†Ô∏è Sync job failed - will try querying documents as fallback`);
          // Continue to document query fallback below
        } else if (jobStatus === 'running' || jobStatus === 'pending') {
          console.log(
            `[AI Search] ‚è≥ Sync job still ${jobStatus} - waiting for completion (attempt ${args.attempt}/${maxAttempts})`,
          );
          // Job is still running, don't mark as indexed yet
          indexed = false;
          waitForJobCompletion = true;
        } else {
          // Job not found (null) or status unknown - check if enough time has passed
          // Cloudflare may clean up completed jobs after some time
          // Timeout matches scheduler runtime (~25 minutes total with backoff)
          const syncStartedAt = submission.source?.aiSearchSyncStartedAt || 0;
          const timeSinceSyncStart = Date.now() - syncStartedAt;
          const MIN_TIME_FOR_JOB_COMPLETION = 25 * 60 * 1000; // 25 minutes (matches scheduler runtime)

          if (syncStartedAt > 0 && timeSinceSyncStart > MIN_TIME_FOR_JOB_COMPLETION) {
            // Job was started but is now not found - likely completed and cleaned up
            console.log(
              `[AI Search] ‚úÖ Job not found but sync started ${Math.round(timeSinceSyncStart / 1000)}s ago (${Math.round(timeSinceSyncStart / 60000)} minutes). Assuming job completed and was cleaned up.`,
            );
            indexed = true;
            // Record sync completion time
            const completedAt = Date.now();
            console.log(
              `[AI Search] Recording sync completion time (job cleanup): ${new Date(completedAt).toISOString()}`,
            );
            await ctx.runMutation(
              (
                internal.submissions as unknown as {
                  updateSubmissionSourceInternal: UpdateSubmissionSourceInternalRef;
                }
              ).updateSubmissionSourceInternal,
              {
                submissionId: args.submissionId,
                aiSearchSyncCompletedAt: completedAt,
              },
            );
            console.log(`[AI Search] ‚úÖ Sync completion recorded successfully (job cleanup)`);
          } else {
            // Job not found and not enough time has passed - fall back to document query
            console.log(
              `[AI Search] ‚è≥ Job status unknown or not found (sync started ${Math.round(timeSinceSyncStart / 1000)}s ago, need ${Math.round(MIN_TIME_FOR_JOB_COMPLETION / 60000)} minutes) - falling back to document query`,
            );
          }
        }
      }

      // If job status check didn't confirm indexing, fall back to querying documents
      // This handles cases where:
      // - No job_id was stored (older submissions)
      // - Job status check failed
      // - Job completed but we want to verify documents are actually indexed
      if (!indexed && !waitForJobCompletion) {
        // If enough time has passed since upload (20+ minutes), assume indexing is complete
        // Timeout matches scheduler runtime to handle long-running Cloudflare sync jobs
        // This handles cases where AI Search is indexed but our query detection isn't working
        const MIN_TIME_FOR_INDEXING = 20 * 60 * 1000; // 20 minutes (matches scheduler runtime)
        if (timeSinceUpload > MIN_TIME_FOR_INDEXING && args.attempt >= 10) {
          console.log(
            `[AI Search] ‚úÖ Files uploaded ${Math.round(timeSinceUpload / 1000)}s ago (${Math.round(timeSinceUpload / 60000)} minutes, attempt ${args.attempt}). Assuming indexing is complete and proceeding.`,
          );
          indexed = true;
        } else {
          console.log(
            `[AI Search] Querying documents to verify indexing (time since upload: ${Math.round(timeSinceUpload / 1000)}s, attempt: ${args.attempt}, need ${Math.round(MIN_TIME_FOR_INDEXING / 60000)} minutes and attempt >= 10 for timeout fallback)`,
          );
          try {
            // Correct endpoint format: /autorag/rags/{instance_name}/ai-search
            const testQueryUrl = `https://api.cloudflare.com/client/v4/accounts/${accountId}/autorag/rags/${aiSearchInstanceId}/ai-search`;
            const folderFilter = buildFolderFilter(r2PathPrefix, args.submissionId);
            type SearchDoc = {
              filename?: string;
              attributes?: { path?: string; folder?: string };
              path?: string;
            };

            console.log('[AI Search] Querying with folder-scoped filter first');
            const filteredResponse = await fetch(testQueryUrl, {
              method: 'POST',
              headers: {
                Authorization: `Bearer ${apiToken}`,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                query: `files in path ${r2PathPrefix} for submission ${args.submissionId}`,
                max_num_results: 50,
                filters: folderFilter,
              }),
            });

            if (filteredResponse.ok) {
              const filteredData = await filteredResponse.json();
              const filteredDocs: SearchDoc[] = (filteredData.data ||
                filteredData.result?.data ||
                []) as SearchDoc[];

              console.log(
                `[AI Search] Filtered query returned ${filteredDocs.length} documents for prefix ${r2PathPrefix}`,
              );

              // Diagnostic: Log metadata structure for first document on first attempt
              if (filteredDocs.length > 0 && args.attempt === 0) {
                console.log(
                  `[AI Search] Diagnostic - first document metadata structure:`,
                  JSON.stringify(filteredDocs[0], null, 2),
                );
              }

              if (filteredDocs.length > 0) {
                const filteredMatches = filteredDocs.filter((doc) => {
                  const docPath = doc.attributes?.path || doc.path || doc.filename || '';
                  return docPath.startsWith(r2PathPrefix);
                });

                const sampleFilteredPaths = filteredDocs.slice(0, 5).map((doc) => ({
                  path: doc.attributes?.path || doc.path || doc.filename || 'Unknown',
                  matchesPrefix: (
                    doc.attributes?.path ||
                    doc.path ||
                    doc.filename ||
                    ''
                  ).startsWith(r2PathPrefix),
                  submissionId:
                    (doc.attributes?.path || doc.path || doc.filename || '').match(
                      /repos\/([^/]+)\//,
                    )?.[1] || 'unknown',
                }));
                console.log(
                  `[AI Search] Sample filtered paths:`,
                  JSON.stringify(sampleFilteredPaths, null, 2),
                );

                if (filteredMatches.length > 0) {
                  console.log(
                    `[AI Search] ‚úÖ Filtered query confirmed ${filteredMatches.length} documents for this submission`,
                  );
                  indexed = true;
                } else {
                  console.warn(
                    `[AI Search] ‚ö†Ô∏è Filtered query returned ${filteredDocs.length} documents but none matched prefix ${r2PathPrefix}`,
                  );
                }
              } else {
                console.log(
                  '[AI Search] Filtered query returned 0 documents - running diagnostic query',
                );
              }
            } else {
              const errorText = await filteredResponse.text();
              console.error(
                `[AI Search] Filtered query failed: ${filteredResponse.status} - ${errorText}`,
              );

              if (
                filteredResponse.status === 400 &&
                (errorText.includes('Could not route') ||
                  errorText.includes('No route for that URI'))
              ) {
                throw new Error(
                  `AI Search instance routing error: The instance "${aiSearchInstanceId}" may not exist or the API endpoint is incorrect. Error: ${errorText}`,
                );
              }
            }

            if (!indexed) {
              const submissionIdInQuery = args.submissionId;
              const diagnosticResponse = await fetch(testQueryUrl, {
                method: 'POST',
                headers: {
                  Authorization: `Bearer ${apiToken}`,
                  'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                  query: `files in path ${r2PathPrefix} for submission ${submissionIdInQuery}`,
                  max_num_results: 50,
                }),
              });

              if (diagnosticResponse.ok) {
                const diagnosticData = await diagnosticResponse.json();
                const diagnosticDocs: SearchDoc[] = (diagnosticData.data ||
                  diagnosticData.result?.data ||
                  []) as SearchDoc[];

                console.log(
                  `[AI Search] Diagnostic query returned ${diagnosticDocs.length} documents - inspecting paths`,
                );

                let logDiagnosticDetail = false;
                if (diagnosticDocs.length > 0) {
                  const samplePaths = diagnosticDocs.slice(0, 10).map((doc) => {
                    const docPath = doc.attributes?.path || doc.path || doc.filename || 'Unknown';
                    const matchesPrefix = docPath.startsWith(r2PathPrefix);
                    return {
                      path: docPath,
                      matchesPrefix,
                      submissionId: docPath.match(/repos\/([^/]+)\//)?.[1] || 'unknown',
                    };
                  });

                  const matchingDocs = samplePaths.filter((p) => p.matchesPrefix).length;
                  logDiagnosticDetail = args.attempt === 0 || args.attempt % 5 === 0;
                  if (logDiagnosticDetail) {
                    const sampleSummary = samplePaths
                      .slice(0, 3)
                      .map((p) => `${p.matchesPrefix ? '‚úì' : '‚úó'} ${p.path}`);
                    console.log(
                      `[AI Search] Diagnostic sample (${matchingDocs}/${samplePaths.length} match target): ${sampleSummary.join('; ')}`,
                    );
                  }
                }

                const mismatchedDocs: Array<{ path: string; submissionId: string }> = [];
                const matchingDocsNoFilter = diagnosticDocs.filter((doc) => {
                  const docPath = doc.attributes?.path || doc.path || doc.filename || '';
                  const matches = docPath.startsWith(r2PathPrefix);
                  if (!matches && docPath.includes('repos/')) {
                    const otherSubmissionId = docPath.match(/repos\/([^/]+)\//)?.[1];
                    if (otherSubmissionId && otherSubmissionId !== args.submissionId) {
                      mismatchedDocs.push({
                        path: docPath,
                        submissionId: otherSubmissionId,
                      });
                    }
                  }
                  return matches;
                });

                if (mismatchedDocs.length > 0) {
                  const uniqueOtherSubmissions = Array.from(
                    new Set(mismatchedDocs.map((doc) => doc.submissionId)),
                  );
                  if (logDiagnosticDetail) {
                    const sampleMismatches = mismatchedDocs
                      .slice(0, 5)
                      .map((doc) => `${doc.submissionId}: ${doc.path}`);
                    console.warn(
                      `[AI Search] ‚ö†Ô∏è Diagnostic query returned ${mismatchedDocs.length} documents from other submissions (${uniqueOtherSubmissions.join(', ')}) while checking ${args.submissionId}. Sample paths: ${sampleMismatches.join('; ')}`,
                    );
                  } else {
                    console.warn(
                      `[AI Search] ‚ö†Ô∏è Diagnostic query returned ${mismatchedDocs.length} documents from other submissions (${uniqueOtherSubmissions.join(', ')}) while checking ${args.submissionId} (suppressed details until attempt divisible by 5).`,
                    );
                  }
                }

                if (matchingDocsNoFilter.length > 0) {
                  console.log(
                    `[AI Search] ‚úÖ Diagnostic query found ${matchingDocsNoFilter.length} matching documents (out of ${diagnosticDocs.length} total) for path prefix ${r2PathPrefix}`,
                  );
                  indexed = true;
                } else if (diagnosticDocs.length > 0) {
                  console.warn(
                    `[AI Search] Diagnostic query returned ${diagnosticDocs.length} documents but none match prefix ${r2PathPrefix}`,
                  );
                } else {
                  console.log(
                    '[AI Search] Diagnostic query returned 0 documents - indexing still warming up',
                  );
                }
              } else {
                const errorText = await diagnosticResponse.text();
                console.error(
                  `[AI Search] Diagnostic query failed: ${diagnosticResponse.status} - ${errorText}`,
                );
              }
            }
          } catch (error) {
            // If query fails with routing error, throw it (don't retry)
            if (error instanceof Error && error.message.includes('routing error')) {
              throw error;
            }

            // For other errors, log but continue
            console.warn(
              `[AI Search] Query error (attempt ${args.attempt}):`,
              error instanceof Error ? error.message : String(error),
            );
          }
        }
      } else if (!indexed && waitForJobCompletion) {
        console.log(
          `[AI Search] ‚è≥ Job ${submission.source?.aiSearchSyncJobId} still ${jobStatus} - skipping document verification until the job finishes.`,
        );
      }

      if (!indexed) {
        // If not indexed and we haven't exceeded max attempts, reschedule
        if (args.attempt < maxAttempts) {
          console.log(
            `[AI Search] ‚è≥ Not indexed yet - rescheduling check in ${pollIntervalMs}ms (attempt ${args.attempt + 1}/${maxAttempts})`,
          );
          await ctx.scheduler.runAfter(
            pollIntervalMs,
            (
              internal.submissionsActions.aiSummary as unknown as {
                checkCloudflareIndexing: CheckCloudflareIndexingRef;
              }
            ).checkCloudflareIndexing,
            {
              submissionId: args.submissionId,
              attempt: args.attempt + 1,
              forceRegenerate: args.forceRegenerate ?? false,
            },
          );
          return; // Exit early, will be called again by scheduler
        } else {
          // Max attempts reached - start continuation polling for long-running jobs
          console.warn(
            `[AI Search] ‚ö†Ô∏è Initial indexing checks exhausted for submission ${args.submissionId} after ${maxAttempts} attempts. Starting continuation polling for long-running jobs.`,
          );

          // Schedule continuation action to keep checking every 5 minutes
          await ctx.scheduler.runAfter(
            0, // Start immediately
            (
              internal.submissionsActions.aiSummary as unknown as {
                continueCloudflareIndexing: ContinueCloudflareIndexingRef;
              }
            ).continueCloudflareIndexing,
            {
              submissionId: args.submissionId,
              continuationAttempt: 1,
              forceRegenerate: args.forceRegenerate ?? false,
            },
          );

          console.log(
            `[AI Search] üîÑ Scheduled continuation polling for submission ${args.submissionId}`,
          );
          return; // Exit without marking complete - continuation will handle completion
        }
      } else {
        // Files are indexed - record sync completion time
        const completedAt = Date.now();
        console.log(
          `[AI Search] ‚úÖ Files confirmed indexed - recording sync completion time: ${new Date(completedAt).toISOString()}`,
        );
        await ctx.runMutation(
          (
            internal.submissions as unknown as {
              updateSubmissionSourceInternal: UpdateSubmissionSourceInternalRef;
            }
          ).updateSubmissionSourceInternal,
          {
            submissionId: args.submissionId,
            aiSearchSyncCompletedAt: completedAt,
          },
        );
        console.log(`[AI Search] ‚úÖ Sync completion recorded successfully`);
      }

      // Files are indexed - mark indexing as complete
      // Only run finalization if we actually found indexed documents (indexed === true)
      if (indexed) {
        // The summary was already generated by generateSummary, so we don't need to generate another one
        console.log(
          `[AI Search] ‚úÖ Indexing complete - marking processing state as complete at ${new Date().toISOString()}`,
        );

        // Set processing state to complete (final check - in case score generation didn't update it)
        console.log(
          `[AI Search] ‚úÖ Finalizing - ensuring processing state is 'complete' at ${new Date().toISOString()}`,
        );
        await ctx.runMutation(
          (
            internal.submissions as unknown as {
              updateSubmissionSourceInternal: UpdateSubmissionSourceInternalRef;
            }
          ).updateSubmissionSourceInternal,
          {
            submissionId: args.submissionId,
            processingState: 'complete',
          },
        );
        console.log(`[AI Search] ‚úÖ Final processing state update complete`);
      }
    } catch (error) {
      // Log error details
      const errorMessage = error instanceof Error ? error.message : String(error);
      console.error(
        `[AI Search] Error checking indexing for submission ${args.submissionId}:`,
        errorMessage,
      );

      // Re-throw so Convex logs it properly
      throw error;
    }
  },
});

/**
 * Diagnostic action to check what paths AI Search is returning for a submission
 * This helps debug path filtering issues
 */
export const diagnoseAISearchPaths = internalAction({
  args: {
    submissionId: v.id('submissions'),
  },
  handler: async (
    ctx: ActionCtx,
    args: { submissionId: Id<'submissions'> },
  ): Promise<{
    error?: string;
    r2PathPrefix: string | null;
    repoUrl?: string;
    totalDocumentsReturned?: number;
    matchingDocuments?: number;
    samplePaths?: Array<{
      filename?: string;
      attributesPath?: string;
      path?: string;
      fullDoc: unknown;
    }>;
    allPaths?: string[];
    pathFilteringWorking?: boolean;
  }> => {
    const submission = await ctx.runQuery(
      (internal.submissions as unknown as { getSubmissionInternal: GetSubmissionInternalRef })
        .getSubmissionInternal,
      {
        submissionId: args.submissionId,
      },
    );

    if (!submission) {
      throw new Error('Submission not found');
    }

    if (!submission.source?.r2Key) {
      return {
        error: 'No R2 files uploaded for this submission',
        r2PathPrefix: null,
      };
    }

    const r2PathPrefix: string = submission.source.r2Key;
    const aiSearchInstanceId = process.env.CLOUDFLARE_AI_SEARCH_INSTANCE_ID;
    const accountId = process.env.CLOUDFLARE_ACCOUNT_ID;
    const apiToken = process.env.CLOUDFLARE_API_TOKEN;

    if (!aiSearchInstanceId || !accountId || !apiToken) {
      throw new Error('Cloudflare AI Search not configured');
    }

    // Correct endpoint format: /autorag/rags/{instance_name}/ai-search
    const queryUrl = `https://api.cloudflare.com/client/v4/accounts/${accountId}/autorag/rags/${aiSearchInstanceId}/ai-search`;

    // Make a test query to see what paths are returned
    // Use server-side filters per API docs: https://developers.cloudflare.com/api/resources/autorag/
    const testResponse: Response = await fetch(queryUrl, {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${apiToken}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        query: `files in ${r2PathPrefix}`,
        max_num_results: 10,
        filters: buildFolderFilter(r2PathPrefix, args.submissionId),
      }),
    });

    if (!testResponse.ok) {
      const errorText = await testResponse.text();
      return {
        error: `Query failed: ${testResponse.status} - ${errorText}`,
        r2PathPrefix,
      };
    }

    const data = (await testResponse.json()) as {
      data?: Array<{
        filename?: string;
        attributes?: { path?: string };
        path?: string;
      }>;
      result?: {
        data?: Array<{
          filename?: string;
          attributes?: { path?: string };
          path?: string;
        }>;
      };
    };
    const documents: Array<{
      filename?: string;
      attributes?: { path?: string };
      path?: string;
    }> = (data.data || data.result?.data || []) as Array<{
      filename?: string;
      attributes?: { path?: string };
      path?: string;
    }>;

    // Extract all paths from documents
    type DocPath = {
      filename?: string;
      attributesPath?: string;
      path?: string;
      fullDoc: unknown;
    };
    const paths: DocPath[] = documents.map(
      (doc: { filename?: string; attributes?: { path?: string }; path?: string }) => {
        return {
          filename: doc.filename,
          attributesPath: doc.attributes?.path,
          path: doc.path,
          fullDoc: doc,
        };
      },
    );

    // Check how many match the prefix
    const matchingPaths = paths.filter((p: DocPath) => {
      const docPath = p.attributesPath || p.path || p.filename || '';
      return docPath.startsWith(r2PathPrefix);
    });

    return {
      r2PathPrefix,
      repoUrl: submission.repoUrl,
      totalDocumentsReturned: documents.length,
      matchingDocuments: matchingPaths.length,
      samplePaths: paths.slice(0, 10),
      allPaths: paths.map((p: DocPath) => p.attributesPath || p.path || p.filename || 'Unknown'),
      pathFilteringWorking: matchingPaths.length > 0 || documents.length === 0,
    };
  },
});

/**
 * Helper function to get R2 credentials
 */
function getR2Credentials(): {
  r2BucketName: string;
  r2AccessKeyId: string;
  r2SecretAccessKey: string;
  r2AccountId: string;
} {
  const r2BucketName = process.env.CLOUDFLARE_R2_BUCKET_NAME;
  const r2AccessKeyId = process.env.CLOUDFLARE_R2_ACCESS_KEY_ID;
  const r2SecretAccessKey = process.env.CLOUDFLARE_R2_SECRET_ACCESS_KEY;
  const r2AccountId = process.env.CLOUDFLARE_ACCOUNT_ID;

  if (!r2BucketName || !r2AccessKeyId || !r2SecretAccessKey || !r2AccountId) {
    throw new Error('R2 credentials not configured');
  }

  return { r2BucketName, r2AccessKeyId, r2SecretAccessKey, r2AccountId };
}

/**
 * Extract README content from R2 files
 * Looks for README.md, README.txt, README, or similar files
 */
async function extractReadmeFromR2(
  r2PathPrefix: string,
): Promise<{ content: string; filename: string } | null> {
  const r2Creds = getR2Credentials();

  const s3Client = new S3Client({
    region: 'auto',
    endpoint: `https://${r2Creds.r2AccountId}.r2.cloudflarestorage.com`,
    credentials: {
      accessKeyId: r2Creds.r2AccessKeyId,
      secretAccessKey: r2Creds.r2SecretAccessKey,
    },
  });

  // List all files in the submission's R2 prefix
  const listCommand = new ListObjectsV2Command({
    Bucket: r2Creds.r2BucketName,
    Prefix: r2PathPrefix,
  });

  const listResponse = await s3Client.send(listCommand);
  const objects = listResponse.Contents || [];

  // Look for README files (case-insensitive, various extensions)
  // Prioritize root-level README, but also check subdirectories
  const readmePatterns = [/^readme\.md$/i, /^readme\.txt$/i, /^readme$/i, /^readme\.markdown$/i];

  // Sort objects to prioritize root-level README files
  const sortedObjects = [...objects].sort((a, b) => {
    if (!a.Key || !b.Key) return 0;
    const aPath = a.Key.replace(r2PathPrefix, '');
    const bPath = b.Key.replace(r2PathPrefix, '');
    const aDepth = aPath.split('/').length;
    const bDepth = bPath.split('/').length;
    return aDepth - bDepth; // Prefer files with fewer path segments (closer to root)
  });

  for (const obj of sortedObjects) {
    if (!obj.Key) continue;

    // Extract filename from R2 key (remove prefix)
    const relativePath = obj.Key.replace(r2PathPrefix, '');
    const filename = relativePath.split('/').pop() || '';

    // Check if this matches a README pattern
    if (readmePatterns.some((pattern) => pattern.test(filename))) {
      try {
        // Download the README file
        const getCommand = new GetObjectCommand({
          Bucket: r2Creds.r2BucketName,
          Key: obj.Key,
        });

        const getResponse = await s3Client.send(getCommand);
        const content = await getResponse.Body?.transformToString();

        if (content) {
          return { content, filename };
        }
      } catch (error) {
        console.warn(`Failed to read README file ${obj.Key}:`, error);
        // Continue to next file
      }
    }
  }

  return null;
}

/**
 * Continuation action for long-running Cloudflare indexing jobs
 * Called when the initial checkCloudflareIndexing hits maxAttempts
 * Polls less frequently (every 5 minutes) to handle jobs taking 30-60+ minutes
 */
export const continueCloudflareIndexing = internalAction({
  args: {
    submissionId: v.id('submissions'),
    continuationAttempt: v.number(),
    forceRegenerate: v.optional(v.boolean()),
  },
  handler: async (ctx, args) => {
    const maxContinuationAttempts = 20; // Allow up to 20 * 5min = 100 minutes additional
    const continuationIntervalMs = 5 * 60 * 1000; // Poll every 5 minutes

    console.log(
      `[AI Search] üîÑ Continuation check for submission ${args.submissionId}, attempt ${args.continuationAttempt}/${maxContinuationAttempts}`,
    );

    // Get submission
    const submission = await ctx.runQuery(
      (internal.submissions as unknown as { getSubmissionInternal: GetSubmissionInternalRef })
        .getSubmissionInternal,
      {
        submissionId: args.submissionId,
      },
    );

    if (!submission) {
      console.warn(`[AI Search] Continuation: Submission ${args.submissionId} not found`);
      return;
    }

    // Check if already completed by another path
    if (submission.source?.aiSearchSyncCompletedAt) {
      console.log(
        `[AI Search] Continuation: Submission ${args.submissionId} already marked complete at ${new Date(submission.source.aiSearchSyncCompletedAt).toISOString()}`,
      );
      return;
    }

    // R2 path prefix for this submission
    const r2PathPrefix = submission.source?.r2Key;
    if (!r2PathPrefix) {
      console.error(
        `[AI Search] Continuation: No R2 path prefix for submission ${args.submissionId} - marking as error`,
      );
      // Mark as error since indexing can't proceed without uploaded files
      await ctx.runMutation(
        (
          internal.submissions as unknown as {
            updateSubmissionSourceInternal: UpdateSubmissionSourceInternalRef;
          }
        ).updateSubmissionSourceInternal,
        {
          submissionId: args.submissionId,
          aiSearchSyncCompletedAt: Date.now(),
          processingState: 'error',
        },
      );
      return;
    }

    // Check Cloudflare AI Search for document count
    const accountId = process.env.CLOUDFLARE_ACCOUNT_ID;
    const aiSearchInstanceId = process.env.CLOUDFLARE_AI_SEARCH_INSTANCE_ID;
    const apiToken = process.env.CLOUDFLARE_API_TOKEN;

    if (!aiSearchInstanceId || !accountId || !apiToken) {
      console.error(
        `[AI Search] Continuation: Cloudflare AI Search not configured - marking as error`,
      );
      // Mark as error since indexing can't proceed without configuration
      await ctx.runMutation(
        (
          internal.submissions as unknown as {
            updateSubmissionSourceInternal: UpdateSubmissionSourceInternalRef;
          }
        ).updateSubmissionSourceInternal,
        {
          submissionId: args.submissionId,
          aiSearchSyncCompletedAt: Date.now(),
          processingState: 'error',
        },
      );
      return;
    }

    try {
      const testQueryUrl = `https://api.cloudflare.com/client/v4/accounts/${accountId}/autorag/rags/${aiSearchInstanceId}/ai-search`;
      const folderFilter = buildFolderFilter(r2PathPrefix, args.submissionId);

      type SearchDoc = {
        filename?: string;
        attributes?: { path?: string; folder?: string };
        path?: string;
      };

      const filteredResponse = await fetch(testQueryUrl, {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${apiToken}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          query: `files in path ${r2PathPrefix} for submission ${args.submissionId}`,
          max_num_results: 10, // Just check if any documents exist
          filters: folderFilter,
        }),
      });

      if (filteredResponse.ok) {
        const filteredData = await filteredResponse.json();
        const filteredDocs: SearchDoc[] = (filteredData.data ||
          filteredData.result?.data ||
          []) as SearchDoc[];

        if (filteredDocs.length > 0) {
          // Found documents - mark as complete
          const completedAt = Date.now();
          console.log(
            `[AI Search] ‚úÖ Continuation found ${filteredDocs.length} indexed documents for submission ${args.submissionId} after ${args.continuationAttempt} continuation attempts`,
          );
          await ctx.runMutation(
            (
              internal.submissions as unknown as {
                updateSubmissionSourceInternal: UpdateSubmissionSourceInternalRef;
              }
            ).updateSubmissionSourceInternal,
            {
              submissionId: args.submissionId,
              aiSearchSyncCompletedAt: completedAt,
              processingState: 'complete',
            },
          );
          console.log(`[AI Search] ‚úÖ Continuation: Processing state marked as complete`);
          return;
        }
      }

      // No documents found yet
      if (args.continuationAttempt < maxContinuationAttempts) {
        // Schedule next continuation check
        console.log(
          `[AI Search] ‚è≥ Continuation: No documents found yet for submission ${args.submissionId}, scheduling next check in ${continuationIntervalMs / 1000}s`,
        );
        await ctx.scheduler.runAfter(
          continuationIntervalMs,
          (
            internal.submissionsActions.aiSummary as unknown as {
              continueCloudflareIndexing: ContinueCloudflareIndexingRef;
            }
          ).continueCloudflareIndexing,
          {
            submissionId: args.submissionId,
            continuationAttempt: args.continuationAttempt + 1,
            forceRegenerate: args.forceRegenerate ?? false,
          },
        );
      } else {
        // Max continuation attempts reached - indexing failed, mark as error
        const completedAt = Date.now();
        console.error(
          `[AI Search] ‚ùå Continuation: Max attempts reached for submission ${args.submissionId} without finding any indexed documents after ${(maxContinuationAttempts * continuationIntervalMs) / 1000 / 60} minutes. Indexing failed.`,
        );
        await ctx.runMutation(
          (
            internal.submissions as unknown as {
              updateSubmissionSourceInternal: UpdateSubmissionSourceInternalRef;
            }
          ).updateSubmissionSourceInternal,
          {
            submissionId: args.submissionId,
            aiSearchSyncCompletedAt: completedAt,
            processingState: 'error',
          },
        );
        console.log(
          `[AI Search] ‚ùå Continuation: Processing state marked as error (indexing failed after max attempts)`,
        );
      }
    } catch (error) {
      console.error(
        `[AI Search] Continuation error for submission ${args.submissionId}:`,
        error instanceof Error ? error.message : String(error),
      );
      // On error, still schedule next continuation unless we've hit max attempts
      if (args.continuationAttempt < maxContinuationAttempts) {
        await ctx.scheduler.runAfter(
          continuationIntervalMs,
          (
            internal.submissionsActions.aiSummary as unknown as {
              continueCloudflareIndexing: ContinueCloudflareIndexingRef;
            }
          ).continueCloudflareIndexing,
          {
            submissionId: args.submissionId,
            continuationAttempt: args.continuationAttempt + 1,
            forceRegenerate: args.forceRegenerate ?? false,
          },
        );
      }
    }
  },
});

/**
 * Generate summary using AI Gateway/Workers with README + screenshots
 * This provides a fast summary before AI Search indexing completes
 */
async function generateSummaryWithAI(
  ctx: ActionCtx,
  submissionId: Id<'submissions'>,
  submissionTitle: string,
  repoUrl: string,
  r2PathPrefix: string | undefined,
): Promise<string> {
  // Import Cloudflare AI helper dynamically to avoid circular dependencies
  // (generateSummaryWithGateway is imported later when needed)

  // Get submission to access screenshots and stored README
  const submission = await ctx.runQuery(
    (internal.submissions as unknown as { getSubmissionInternal: GetSubmissionInternalRef })
      .getSubmissionInternal,
    {
      submissionId,
    },
  );

  if (!submission) {
    throw new Error('Submission not found');
  }

  // Use stored README if available (fetched from GitHub), otherwise try to extract from R2
  let readmeContent: string | null = null;
  let readmeFilename: string | null = null;

  // Prefer stored README (fetched directly from GitHub)
  if (submission.source?.readme) {
    readmeContent = submission.source.readme;
    readmeFilename = submission.source.readmeFilename || 'README.md';
    console.log(
      `[Early Summary] Using stored README (${readmeFilename}) for submission ${submissionId}`,
    );
  } else if (r2PathPrefix) {
    // Fallback to extracting from R2 if stored README not available
    try {
      const readmeResult = await extractReadmeFromR2(r2PathPrefix);
      if (readmeResult) {
        readmeContent = readmeResult.content;
        readmeFilename = readmeResult.filename;
        console.log(
          `[Early Summary] Extracted README from R2 (${readmeFilename}) for submission ${submissionId}`,
        );
      }
    } catch (error) {
      console.warn(
        `[Early Summary] Failed to extract README from R2 for submission ${submissionId}:`,
        error instanceof Error ? error.message : String(error),
      );
      // Continue without README
    }
  }

  // Get screenshots
  const screenshots = submission.screenshots || [];
  const screenshotUrls = screenshots
    .map((s) => s.url)
    .filter((url): url is string => typeof url === 'string' && url.length > 0);

  // Get video URL
  const videoUrl = (submission as { videoUrl?: string }).videoUrl?.trim();

  // Build prompt with README, screenshots, and video
  const repoName = repoUrl.match(/github\.com[:/]+([^/]+)\/([^/#?]+)/i)?.[2] || 'unknown';

  let prompt = `You are an expert hackathon judge analyzing a submission. Generate a comprehensive summary of this project based on the available information.\n\n`;
  prompt += `**Project Details:**\n`;
  prompt += `- Title: ${submissionTitle}\n`;
  prompt += `- Repository: ${repoUrl}\n`;
  prompt += `- Repository Name: ${repoName}\n`;

  if (readmeContent) {
    prompt += `\n**GitHub README (${readmeFilename}):**\n\`\`\`\n${readmeContent.slice(0, 8000)}\n\`\`\`\n`;
    // Limit README to 8000 chars to avoid token limits
  } else {
    prompt += `\n**Note:** No README file was found in the repository.\n`;
  }

  if (screenshotUrls.length > 0) {
    prompt += `\n**Live Site Screenshots:**\n`;
    prompt += `The project has ${screenshotUrls.length} screenshot(s) of the live site:\n`;
    screenshotUrls.forEach((url, idx) => {
      prompt += `${idx + 1}. ${url}\n`;
    });
    prompt += `\nThese screenshots show the actual user interface and functionality of the application.\n`;
  } else {
    prompt += `\n**Note:** No screenshots of the live site are available.\n`;
  }

  if (videoUrl) {
    prompt += `\n**Demo Video:**\n`;
    prompt += `The project includes a demo video that showcases the application in action:\n`;
    prompt += `${videoUrl}\n\n`;
    prompt += `IMPORTANT: Analyze this video to understand:\n`;
    prompt += `- User interface and user experience in action\n`;
    prompt += `- Key functionality demonstrations and workflows\n`;
    prompt += `- Visual design, animations, and aesthetics\n`;
    prompt += `- How users interact with the application\n`;
    prompt += `- Any spoken explanations, tutorials, or audio content\n\n`;
  }

  prompt += `\n**Your Task:**\n`;
  prompt += `Generate a concise summary with these three fields as JSON:\n\n`;
  prompt += `1. mainPurpose: Brief description (2-3 sentences max)\n`;
  prompt += `2. keyTechnologiesAndFrameworks: Markdown bullet list (max 8 items, keep descriptions short)\n`;
  prompt += `3. mainFeaturesAndFunctionality: Markdown bullet list of key features (max 10 items, keep descriptions short)\n\n`;
  prompt += `Keep responses concise to fit within token limits. Be specific and reference README, screenshots, and video content.\n`;

  try {
    // Import the structured output helper
    const { generateSummaryWithGateway } = await import('../cloudflareAi');

    // Generate structured summary using AI Gateway with Google AI Studio Gemini Flash Lite (ensures all sections are present)
    // Uses Provider Keys configured in AI Gateway dashboard
    const result = await generateSummaryWithGateway(prompt, {
      useGoogleAI: true,
      geminiModel: 'models/gemini-flash-lite-latest',
    });

    // Format the structured output as markdown
    const summary = `${result.summary.mainPurpose}\n\n**Main Features and Functionality:**\n\n${result.summary.mainFeaturesAndFunctionality}\n\n**Key Technologies and Frameworks:**\n\n${result.summary.keyTechnologiesAndFrameworks}`;

    console.log(`[Early Summary] Generated structured summary with all three sections`);
    console.log(`[Early Summary] Finish reason: ${result.finishReason}`);

    return summary;
  } catch (error) {
    const errorMessage =
      error instanceof Error ? error.message : 'Failed to generate summary with AI Gateway';

    console.error(`[Early Summary] AI Gateway error for submission ${submissionId}:`, errorMessage);
    console.error(`[Early Summary] Full error:`, error);

    // Try fallback to text generation if structured output fails
    try {
      console.log(`[Early Summary] Attempting fallback to text generation...`);
      const { generateWithGatewayHelper } = await import('../cloudflareAi');
      const fallbackResult = await generateWithGatewayHelper(prompt, 'llama');

      // Try to parse the text response as JSON or extract sections
      const text = fallbackResult.response;

      // Check if it's already in the right format
      if (
        text.includes('**Key Technologies and Frameworks:**') &&
        text.includes('**Main Features and Functionality:**')
      ) {
        console.log(`[Early Summary] Fallback text generation produced valid format`);
        // Strip "**Main Purpose:**" if present since we don't want that label
        const cleanedText = text.replace(/^\*\*Main Purpose:\*\*\s*\n\n?/i, '');
        return cleanedText;
      }

      // If not, return error message
      throw new Error('Fallback text generation did not produce expected format');
    } catch (fallbackError) {
      console.error(`[Early Summary] Fallback also failed:`, fallbackError);

      // Return a fallback summary with the three sections
      return `Unable to generate summary due to error: ${errorMessage}. The full repository summary will be available once Cloudflare AI Search finishes indexing the repository files.\n\n**Main Features and Functionality:**\n\nInformation not available.\n\n**Key Technologies and Frameworks:**\n\nInformation not available.`;
    }
  }
}

/**
 * Helper function to generate early summary (extracted so it can be called from both internal and public actions)
 */
async function generateSummaryHelper(
  ctx: ActionCtx,
  args: { submissionId: Id<'submissions'>; forceRegenerate?: boolean },
): Promise<{
  success: boolean;
  skipped?: boolean;
  summary?: string;
  error?: string;
  reason?: string;
}> {
  const submission = await ctx.runQuery(
    (internal.submissions as unknown as { getSubmissionInternal: GetSubmissionInternalRef })
      .getSubmissionInternal,
    {
      submissionId: args.submissionId,
    },
  );

  if (!submission) {
    throw new Error('Submission not found');
  }

  // Check if summary already exists (skip only if not forcing regeneration)
  // Note: aiSummary can contain either early summary or AI Search summary
  if (submission.source?.aiSummary && !args.forceRegenerate) {
    console.log(`[Early Summary] Submission ${args.submissionId} already has a summary - skipping`);
    return { success: true, skipped: true };
  }

  // If forcing regeneration, clear existing summary first
  if (args.forceRegenerate && submission.source?.aiSummary) {
    console.log(
      `[Early Summary] Force regenerating early summary for submission ${args.submissionId} - clearing existing summary`,
    );
    await ctx.runMutation(
      (
        internal.submissions as unknown as {
          updateSubmissionSourceInternal: UpdateSubmissionSourceInternalRef;
        }
      ).updateSubmissionSourceInternal,
      {
        submissionId: args.submissionId,
        aiSummary: undefined,
        summarizedAt: undefined,
        summaryGenerationStartedAt: undefined,
        summaryGenerationCompletedAt: undefined,
      },
    );
  }

  // Check if we have at least README (stored or in R2), R2 files, or screenshots to work with
  const hasStoredReadme = !!submission.source?.readme;
  const hasR2Files = !!submission.source?.r2Key;
  const hasScreenshots = (submission.screenshots?.length ?? 0) > 0;

  if (!hasStoredReadme && !hasR2Files && !hasScreenshots) {
    console.log(
      `[Early Summary] Submission ${args.submissionId} has no README, R2 files, or screenshots yet - skipping`,
    );
    return { success: false, reason: 'No README, R2 files, or screenshots available' };
  }

  try {
    // Set processing state to generating
    await ctx.runMutation(
      (
        internal.submissions as unknown as {
          updateSubmissionSourceInternal: UpdateSubmissionSourceInternalRef;
        }
      ).updateSubmissionSourceInternal,
      {
        submissionId: args.submissionId,
        processingState: 'generating',
        summaryGenerationStartedAt: Date.now(),
      },
    );

    // Generate early summary
    const summary = await generateSummaryWithAI(
      ctx,
      args.submissionId,
      submission.title,
      submission.repoUrl,
      submission.source?.r2Key,
    );

    // Update submission with early summary (store in aiSummary field)
    const summaryGenerationCompletedAt = Date.now();
    await ctx.runMutation(
      (
        internal.submissions as unknown as {
          updateSubmissionSourceInternal: UpdateSubmissionSourceInternalRef;
        }
      ).updateSubmissionSourceInternal,
      {
        submissionId: args.submissionId,
        aiSummary: summary,
        summarizedAt: summaryGenerationCompletedAt,
        summaryGenerationCompletedAt,
        processingState: 'indexing', // Back to indexing while waiting for AI Search
      },
    );

    console.log(
      `[Early Summary] Generated early summary for submission ${args.submissionId} using README + screenshots`,
    );

    return { success: true, summary };
  } catch (error) {
    const errorMessage =
      error instanceof Error ? error.message : 'Failed to generate early summary';

    console.error(`[Early Summary] Error for submission ${args.submissionId}:`, errorMessage);

    // Don't throw - allow AI Search summary to be generated later
    return { success: false, error: errorMessage };
  }
}

/**
 * Generate early summary using README + screenshots (before AI Search indexing completes)
 * This provides immediate feedback while waiting for full repository indexing
 */
export const generateSummary = internalAction({
  args: {
    submissionId: v.id('submissions'),
    forceRegenerate: v.optional(v.boolean()), // If true, regenerate even if summary exists
  },
  handler: async (ctx, args) => {
    return await generateSummaryHelper(ctx, args);
  },
});

/**
 * Generate summary using only screenshots (for submissions without repo URLs)
 */
export const generateScreenshotOnlySummary = internalAction({
  args: {
    submissionId: v.id('submissions'),
  },
  handler: async (ctx, args) => {
    try {
      const submission = await ctx.runQuery(
        (internal.submissions as unknown as { getSubmissionInternal: GetSubmissionInternalRef })
          .getSubmissionInternal,
        {
          submissionId: args.submissionId,
        },
      );

      if (!submission) {
        console.warn(`[Screenshot Summary] Submission ${args.submissionId} not found`);
        return;
      }

      const hasSiteUrl = !!submission.siteUrl?.trim();
      const hasScreenshots = (submission.screenshots?.length ?? 0) > 0;
      const hasSummary = !!submission.source?.aiSummary;

      // Only generate if we have siteUrl, screenshots, and no existing summary
      if (hasSiteUrl && hasScreenshots && !hasSummary) {
        console.log(
          `[Screenshot Summary] Generating summary from screenshots only for submission ${args.submissionId}`,
        );
        await ctx.scheduler.runAfter(
          0,
          (
            internal.submissionsActions.aiSummary as unknown as {
              generateSummary: GenerateSummaryRef;
            }
          ).generateSummary,
          {
            submissionId: args.submissionId,
            forceRegenerate: false,
          },
        );
      } else {
        console.log(
          `[Screenshot Summary] Skipping screenshot-only summary for submission ${args.submissionId}: siteUrl=${hasSiteUrl}, screenshots=${hasScreenshots}, hasSummary=${hasSummary}`,
        );
      }
    } catch (error) {
      console.error(
        `[Screenshot Summary] Failed to generate screenshot-only summary for submission ${args.submissionId}:`,
        error instanceof Error ? error.message : String(error),
      );
    }
  },
});

/**
 * Helper function to generate repo summary (download/upload if needed, then schedule indexing check)
 * Extracted so it can be called from both generateRepoSummary and processSubmission
 */
async function generateRepoSummaryHelper(
  ctx: ActionCtx,
  args: { submissionId: Id<'submissions'>; forceRegenerate?: boolean },
): Promise<{ scheduled: boolean }> {
  // Check if repo has been uploaded
  const submission = await ctx.runQuery(
    (internal.submissions as unknown as { getSubmissionInternal: GetSubmissionInternalRef })
      .getSubmissionInternal,
    {
      submissionId: args.submissionId,
    },
  );

  if (!submission) {
    throw new Error('Submission not found');
  }

  // If there's no repo URL, generate screenshot-only summary instead
  if (!submission.repoUrl?.trim()) {
    console.log(
      `[Repo Summary] No repo URL for submission ${args.submissionId}, generating screenshot-only summary`,
    );
    await ctx.scheduler.runAfter(
      0,
      internal.submissionsActions.aiSummary.generateScreenshotOnlySummary,
      {
        submissionId: args.submissionId,
      },
    );
    return { scheduled: true };
  }

  // If repo hasn't been uploaded, do it now using the helper function
  if (!submission.source?.r2Key) {
    await downloadAndUploadRepoHelper(ctx, {
      submissionId: args.submissionId,
    });
  }

  // Schedule the internal action to check indexing
  await ctx.scheduler.runAfter(
    0,
    (
      internal.submissionsActions.aiSummary as unknown as {
        checkCloudflareIndexing: CheckCloudflareIndexingRef;
      }
    ).checkCloudflareIndexing,
    {
      submissionId: args.submissionId,
      attempt: 0,
      forceRegenerate: args.forceRegenerate ?? false,
    },
  );

  return { scheduled: true };
}

/**
 * Public action wrapper for generating summary (README + screenshots)
 * This provides fast summary generation without waiting for AI Search indexing
 */
export const generateSummaryPublic = guarded.action(
  'submission.write',
  {
    submissionId: v.id('submissions'),
    forceRegenerate: v.optional(v.boolean()), // If true, regenerate even if summary exists
  },
  async (ctx, args, _role) => {
    return await generateSummaryHelper(ctx, {
      submissionId: args.submissionId,
      forceRegenerate: args.forceRegenerate ?? false,
    });
  },
);

/**
 * Public action wrapper for generating repository summary using AI Search
 * Handles download/upload if needed, then schedules the internal polling action to check indexing status
 * This combines download/upload and summary scheduling in one action to avoid cross-action calls
 * Uses Cloudflare AI Search to analyze all repository files for comprehensive summary
 */
export const generateRepoSummary = guarded.action(
  'submission.write',
  {
    submissionId: v.id('submissions'),
    forceRegenerate: v.optional(v.boolean()), // If true, regenerate even if summary exists
  },
  async (ctx, args, _role) => {
    return await generateRepoSummaryHelper(ctx, {
      submissionId: args.submissionId,
      forceRegenerate: args.forceRegenerate ?? false,
    });
  },
);
